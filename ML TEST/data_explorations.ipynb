{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Kernel \n",
    "\n",
    "Name: spri (python 3.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello, world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENV Setup and Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import torch\n",
    "import sklearn\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YFinance Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"TSLA\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = '60d', interval = '30m') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "rec = stock.recommendations.to_dict(\"records\") #has the recommendations on what to do with the stock \n",
    "#print(rec)\n",
    "\n",
    "\n",
    "news = stock.news #Has all of the news from the yahoo finance page \n",
    "#print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.info\n",
    "key_to_display = ['city', 'state', 'country', 'industry', 'website', 'phone', 'companyOfficers', 'open' , 'previousClose', 'Percentage diff', #for this % diff, just find the how percentage is the opena nd prev close diff\n",
    "                  'marketCap', 'currency', 'longName', 'timeZoneFullName', 'recommendationKey'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['companyOfficers'][0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_price = info.get('currentPrice')\n",
    "old_price = stock.info['previousClose']\n",
    "percentage_change = ((new_price - old_price) / old_price) * 100\n",
    "print(str(percentage_change))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.info['recommendationKey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.major_holders.to_dict()['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_to_display = ['title', 'publisher', 'link', 'relatedTickers', 'thumbnail'] #thumbnail is a dict and you gon get the url like this. stock.news[1]['thumbnail']['resolutions'][0]['url']\n",
    "\n",
    "stock.news[1]['thumbnail']['resolutions'][0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down = stock.upgrades_downgrades\n",
    "down.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.upgrades_downgrades.iloc[:3].reset_index().loc[:, ['Firm', 'ToGrade', 'GradeDate']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Timestamp('2024-03-31 00:00:00'): 21301000000.0,\n",
       "  Timestamp('2023-12-31 00:00:00'): 25167000000.0,\n",
       "  Timestamp('2023-09-30 00:00:00'): 23350000000.0,\n",
       "  Timestamp('2023-06-30 00:00:00'): 24927000000.0,\n",
       "  Timestamp('2023-03-31 00:00:00'): 23329000000.0},\n",
       " {Timestamp('2024-03-31 00:00:00'): 3696000000.0,\n",
       "  Timestamp('2023-12-31 00:00:00'): 4438000000.0,\n",
       "  Timestamp('2023-09-30 00:00:00'): 4178000000.0,\n",
       "  Timestamp('2023-06-30 00:00:00'): 4533000000.0,\n",
       "  Timestamp('2023-03-31 00:00:00'): 4511000000.0},\n",
       " {Timestamp('2024-03-31 00:00:00'): 1129000000.0,\n",
       "  Timestamp('2023-12-31 00:00:00'): 7930000000.0,\n",
       "  Timestamp('2023-09-30 00:00:00'): 1853000000.0,\n",
       "  Timestamp('2023-06-30 00:00:00'): 2703000000.0,\n",
       "  Timestamp('2023-03-31 00:00:00'): 2513000000.0},\n",
       " {Timestamp('2024-03-31 00:00:00'): 17605000000.0,\n",
       "  Timestamp('2023-12-31 00:00:00'): 20729000000.0,\n",
       "  Timestamp('2023-09-30 00:00:00'): 19172000000.0,\n",
       "  Timestamp('2023-06-30 00:00:00'): 20394000000.0,\n",
       "  Timestamp('2023-03-31 00:00:00'): 18818000000.0},\n",
       " {Timestamp('2024-03-31 00:00:00'): 21301000000.0,\n",
       "  Timestamp('2023-12-31 00:00:00'): 25167000000.0,\n",
       "  Timestamp('2023-09-30 00:00:00'): 23350000000.0,\n",
       "  Timestamp('2023-06-30 00:00:00'): 24927000000.0,\n",
       "  Timestamp('2023-03-31 00:00:00'): 23329000000.0},\n",
       " {Timestamp('2024-03-31 00:00:00'): 20130000000.0,\n",
       "  Timestamp('2023-12-31 00:00:00'): 23103000000.0,\n",
       "  Timestamp('2023-09-30 00:00:00'): 21586000000.0,\n",
       "  Timestamp('2023-06-30 00:00:00'): 22528000000.0,\n",
       "  Timestamp('2023-03-31 00:00:00'): 20665000000.0}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.quarterly_financials.loc[['Total Revenue','Gross Profit', 'Net Income' ,'Cost Of Revenue', 'Operating Revenue', 'Total Expenses']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Total Revenue','Gross Profit', 'Net Income' ,'Cost Of Revenue', 'Operating Revenue', 'Total Expenses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINKS:\n",
    "\n",
    "https://pypi.org/project/yfinance/\n",
    "\n",
    "https://finance.yahoo.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explorations and Idea of Attack \n",
    "\n",
    "Now, we got all of these details, how are they going to be used in our model, and what is our model? \n",
    "\n",
    "Data:\n",
    "Open: Opening stock price of the unit time \n",
    "Close: Closing stock price of the unit time \n",
    "High: Highest stock price of the unit time\n",
    "Low: Lowest stock price of the unit time \n",
    "Volume: Amount of stocks sold in that unit time.\n",
    "\n",
    "Plan of Attack :\n",
    "\n",
    "Plan 1: Time series graph: Basically take the Open and Close values and then find the mid value and plot a time series graph and then involue LSTMS for time series grpahs. Good for long forcasts for over a week in the future or so. (Link 2)\n",
    "\n",
    "Plan 2: Timely Update Graph: Take the open, high and low as X and Close as Y and perform normal LSTM operations. (Link 3)\n",
    "\n",
    "If you are predicting intraday trading and your interval is 1 min, you need to automatically cache and update the timer and predict the values for the minute. So, you might have to turn your model to Train mode and then feed in this additional info and then turn it back to test mode and predict the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized = (hist - hist.min()) / (hist.max() - hist.min())\n",
    "\n",
    "Y = hist_normalized['Close']\n",
    "X = hist_normalized.drop('Close', axis=1)\n",
    "X = X.drop('Dividends', axis=1)\n",
    "X = X.drop('Stock Splits', axis=1)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values = X.values\n",
    "\n",
    "#1 is the time step, if you need the lstm to look back the past 1 row and then predict the closing price. then the time step should be 1. \n",
    "#if you want the lstm to look back around the past 5 records and then the predict the closing price, then turn the 1 into a 5\n",
    "X_reshape = X_Values.reshape((X_Values.shape[0], 1, X_Values.shape[1]))\n",
    "print(X_reshape.shape)\n",
    "X_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Links\n",
    "\n",
    "1. https://colab.research.google.com/drive/18WiSw1K0BW3jOKO56vxn11Fo9IyOuRjh#scrollTo=2SoQJk5BYOas\n",
    "\n",
    "2. https://www.datacamp.com/tutorial/lstm-python-stock-market \n",
    "\n",
    "3. https://medium.com/@prajjwalchauhan94017/stock-prediction-and-forecasting-using-lstm-long-short-term-memory-9ff56625de73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (For plan 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.0, random_state=42)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inference = np.array([[[0.09978002, 0.07600253, 0.10062503, 0.        ]]])\n",
    "pred = model(Inference)\n",
    "yhat_unnormalized = pred.numpy().tolist()[0][0] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "ytrue_unnmormalized = Y.values[-1] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "print(yhat_unnormalized, ytrue_unnmormalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: The data isn't predicting the future but the time that is already passed. \n",
    "\n",
    "* What you need to do is, instead of giving the y as the close price of that row, give the y as the close price of the next row. aka the close price of the next time step. basically you are removing the top value of the close and shifting the total col up by 1 row (this means the first x is pared with the 2nd y and 2nd x is pared by 3rd y and like that the last x won't have an y value) and removing the last x and the using that as the inference x. This might not need testing dataset. \n",
    "\n",
    "\n",
    "* or keep everything the same and then take the current, open, high and low price by web scrapping and then predict using that. \n",
    "\n",
    "* what you need to is, take 1m as the interval and turn the time step into 30 (so each input is around 30 mintues' worth of data and then you predict the close of the once every 30 mins) (Didn't do exactly this but did 30 min interval and then turn that into 1.5 hour time step.)\n",
    "\n",
    "\n",
    "\n",
    "* Or just use the open price as x and then web scrap the current price and name it as current open price and then get the y value\n",
    "\n",
    "\n",
    "Not sure if all of these will work, but try all of them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 1 (SORTA WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"GC=F\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = '60d', interval = '30m') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "#opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "#inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "#rec = stock.recommendations #has the recommendations on what to do with the stock \n",
    "#print(rec)\n",
    "\n",
    "#BS = stock.balancesheet #Has the balance sheet. \n",
    "#print(BS)\n",
    "\n",
    "#news = stock.news #Has all of the news from the yahoo finance page \n",
    "#print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized .index = pd.to_datetime(hist_normalized .index)\n",
    "\n",
    "# Resample the data to hourly intervals\n",
    "hourly_data = hist_normalized .resample('H').agg({'Open': 'first',\n",
    "                                      'High': 'max',\n",
    "                                      'Low': 'min',\n",
    "                                      'Close': 'last',\n",
    "                                      'Volume': 'sum'})\n",
    "\n",
    "# The 'Dividends' and 'Stock Splits' columns are not applicable for hourly data\n",
    "# and can be dropped or handled as needed\n",
    "\n",
    "hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized = (hist - hist.min()) / (hist.max() - hist.min())\n",
    "\n",
    "Y = hist_normalized['Close'].iloc[1:]\n",
    "X = hist_normalized.drop('Close', axis=1)\n",
    "X = X.drop('Dividends', axis=1)\n",
    "X = X.drop('Stock Splits', axis=1)\n",
    "Inference = X.iloc[-1]\n",
    "X = X.iloc[:-1]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inference.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values = X.values\n",
    "In = Inference.values\n",
    "In = In.reshape((1, 1, In.shape[0]))\n",
    "\n",
    "#1 is the time step, if you need the lstm to look back the past 1 row and then predict the closing price. then the time step should be 1. \n",
    "#if you want the lstm to look back around the past 5 records and then the predict the closing price, then turn the 1 into a 5\n",
    "X_reshape = X_Values.reshape((X_Values.shape[0], 1, X_Values.shape[1]))\n",
    "print(X_reshape.shape)\n",
    "X_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the data\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.0, random_state=42)\n",
    "# X_train, y_train = X_reshape, Y\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "\n",
    "# # Define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=100)\n",
    "# # Evaluate the model\n",
    "# #loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #print('Test loss:', loss)\n",
    "\n",
    "## Test 2 \n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "\n",
    "def custom_activation(x, beta = 1):\n",
    "        return (K.sigmoid(beta * x) * x)\n",
    "\n",
    "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.15, random_state=42)\n",
    "#X_train, y_train = X_reshape, tY\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Activation(custom_activation,name = \"Swish\"))\n",
    "model.add(Dense(1))\n",
    "#print(model.summary())\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(np.array([[Inference.values.tolist()]]))\n",
    "yhat_unnormalized = pred.numpy().tolist()[0][0] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "#ytrue_unnmormalized = 0.02574494974900854 * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "print(yhat_unnormalized) #this value is the predicted value that is in the next timestep future.\n",
    "#that is the price of the stock in around 2024-04-19 16:00:00-40:00. the predicted price was 398.227. \n",
    "# the actual price at that time was 399.12\n",
    "# the actual stock is actually decreasing.\n",
    "\n",
    "#Now doing for an hour. the the predicted was 398.44\n",
    "# the actual price was. 398.38. which is not bad at all!!!!!!!!! \n",
    "\n",
    "\n",
    "#Test number two. \n",
    "# one hour. the predicted was 399.94. the true was 399.119 and the price is increasing\n",
    "# 30 mins. The predicted was 399.03 and the true was 399.109. Both were done for msft stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 2 (Don't think will work.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 3 (Works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"msft\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = '1mo', interval = '30m') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "#opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "#inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "rec = stock.recommendations #has the recommendations on what to do with the stock \n",
    "print(rec)\n",
    "\n",
    "#BS = stock.balancesheet #Has the balance sheet. \n",
    "#print(BS)\n",
    "\n",
    "news = stock.news #Has all of the news from the yahoo finance page \n",
    "print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized = (hist - hist.min()) / (hist.max() - hist.min())\n",
    "\n",
    "Y = hist_normalized['Close'].iloc[1:]\n",
    "X = hist_normalized.drop('Close', axis=1)\n",
    "X = X.drop('Dividends', axis=1)\n",
    "X = X.drop('Stock Splits', axis=1)\n",
    "Inference = X.iloc[-1]\n",
    "X = X.iloc[:-1]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming X_Values is your original data\n",
    "X_Values = X.values\n",
    "\n",
    "# Initialize an empty list to hold the reshaped data\n",
    "X_reshape = []\n",
    "\n",
    "TimeStep = 0 #0 means only the current row, 1 means 1 previous row included. 2 means 2 previous rows included. \n",
    "# Loop through each row in the dataset\n",
    "for i in range(TimeStep, X_Values.shape[0]):\n",
    "    # Create a window of data that includes the current row and the two preceding rows\n",
    "    window = X_Values[i-TimeStep:i+1]\n",
    "    # Reshape the window to fit the LSTM model's input shape\n",
    "    window_reshaped = window.reshape((1, window.shape[0], window.shape[1]))\n",
    "    # Append the reshaped window to the list\n",
    "    X_reshape.append(window_reshaped)\n",
    "\n",
    "# Convert the list of reshaped windows to a NumPy array\n",
    "X_reshape = np.concatenate(X_reshape, axis=0)\n",
    "\n",
    "print(X_reshape.shape)\n",
    "\n",
    "Y = Y.iloc[TimeStep:]\n",
    "\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.0, random_state=42)\n",
    "X_train, y_train = X_reshape, Y\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "# Evaluate the model\n",
    "#loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "#print('Test loss:', loss)\n",
    "\n",
    "## Test 2 \n",
    "# from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "# from keras import backend as K\n",
    "# from keras.layers import Activation\n",
    "\n",
    "# def custom_activation(x, beta = 1):\n",
    "#         return (K.sigmoid(beta * x) * x)\n",
    "\n",
    "# get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
    "\n",
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.15, random_state=42)\n",
    "# #X_train, y_train = X_reshape, tY\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "\n",
    "# # Define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(Activation(custom_activation,name = \"Swish\"))\n",
    "# model.add(Dense(1))\n",
    "# #print(model.summary())\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=100)\n",
    "# # Evaluate the model\n",
    "# loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Test loss:', loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In = X_reshape[-1]\n",
    "In = np.delete(In, 0, axis=0)\n",
    "In = np.append(In, np.array([Inference.values.tolist()]), axis=0)\n",
    "In = In[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(In)\n",
    "yhat_unnormalized = pred.numpy().tolist()[0][0] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "#ytrue_unnmormalized = 0.02574494974900854 * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "print(yhat_unnormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 4 (Should try)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 5 (1 Day model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"MSFT\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = '1y', interval = '1d') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "rec = stock.recommendations #has the recommendations on what to do with the stock \n",
    "#print(rec)\n",
    "\n",
    "BS = stock.balancesheet #Has the balance sheet. \n",
    "#print(BS)\n",
    "\n",
    "news = stock.news #Has all of the news from the yahoo finance page \n",
    "#print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named 1 for object type Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\yaesh\\anaconda3\\envs\\spri\\lib\\site-packages\\pandas\\core\\generic.py:513\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_AXIS_TO_AXIS_NUMBER\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m hist_normalized \u001b[38;5;241m=\u001b[39m (hist \u001b[38;5;241m-\u001b[39m hist\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (hist\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m hist\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m----> 2\u001b[0m hist_inference \u001b[38;5;241m=\u001b[39m \u001b[43mhist_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m hist_normalized \u001b[38;5;241m=\u001b[39m hist_normalized\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m Y \u001b[38;5;241m=\u001b[39m hist_normalized[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yaesh\\anaconda3\\envs\\spri\\lib\\site-packages\\pandas\\core\\series.py:5085\u001b[0m, in \u001b[0;36mSeries.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4989\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4990\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4997\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4998\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4999\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5000\u001b[0m \u001b[38;5;124;03m    Return Series with specified index labels removed.\u001b[39;00m\n\u001b[0;32m   5001\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5083\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   5084\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5087\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5091\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5092\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5093\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yaesh\\anaconda3\\envs\\spri\\lib\\site-packages\\pandas\\core\\generic.py:4534\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4533\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4534\u001b[0m     axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_axis_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4535\u001b[0m     axes \u001b[38;5;241m=\u001b[39m {axis_name: labels}\n\u001b[0;32m   4536\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yaesh\\anaconda3\\envs\\spri\\lib\\site-packages\\pandas\\core\\generic.py:520\u001b[0m, in \u001b[0;36mNDFrame._get_axis_name\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_axis_name\u001b[39m(\u001b[38;5;28mcls\u001b[39m, axis: Axis) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 520\u001b[0m     axis_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_axis_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS[axis_number]\n",
      "File \u001b[1;32mc:\\Users\\yaesh\\anaconda3\\envs\\spri\\lib\\site-packages\\pandas\\core\\generic.py:515\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo axis named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for object type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No axis named 1 for object type Series"
     ]
    }
   ],
   "source": [
    "hist_normalized = (hist - hist.min()) / (hist.max() - hist.min())\n",
    "hist_inference = hist_normalized.iloc[-1]\n",
    "hist_normalized = hist_normalized.iloc[:-1]\n",
    "\n",
    "Y = hist_normalized['Close']\n",
    "X = hist_normalized.drop('Close', axis=1)\n",
    "X = X.drop('Dividends', axis=1)\n",
    "X = X.drop('Stock Splits', axis=1)\n",
    "\n",
    "\n",
    "X_Values = X.values\n",
    "\n",
    "#1 is the time step, if you need the lstm to look back the past 1 row and then predict the closing price. then the time step should be 1. \n",
    "#if you want the lstm to look back around the past 5 records and then the predict the closing price, then turn the 1 into a 5\n",
    "X_reshape = X_Values.reshape((X_Values.shape[0], 1, X_Values.shape[1]))\n",
    "print(X_reshape.shape)\n",
    "X_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 7s 9ms/step - loss: 0.2805\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2420\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2075\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1726\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1405\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1104\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0802\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0544\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0223\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0157\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0133\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0115\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0101\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0065\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0047\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0028\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0020\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0017\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0014\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0012\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.9693e-04\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.2706e-04\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.7357e-04\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.3520e-04\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.0163e-04\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.7503e-04\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.5411e-04\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.3423e-04\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.1441e-04\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.9798e-04\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.8564e-04\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7367e-04\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.6096e-04\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.5213e-04\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.3963e-04\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.3126e-04\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.2489e-04\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.1620e-04\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.0969e-04\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.0257e-04\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.9789e-04\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.9245e-04\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.8851e-04\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.8420e-04\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.8116e-04\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.7837e-04\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.7494e-04\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.7248e-04\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.6945e-04\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.6835e-04\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.6491e-04\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.6129e-04\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.6129e-04\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.5906e-04\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.5629e-04\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.5489e-04\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.5267e-04\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.5194e-04\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.4978e-04\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.4839e-04\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.4624e-04\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.5050e-04\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.4887e-04\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.4534e-04\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.4140e-04\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.3876e-04\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.3694e-04\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.4052e-04\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.3353e-04\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.3430e-04\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.3191e-04\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.3142e-04\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 5.2965e-04\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 5.2818e-04\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.2769e-04\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.2670e-04\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.2514e-04\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.2372e-04\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.2279e-04\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.2103e-04\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.2033e-04\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.1955e-04\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.1790e-04\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.1762e-04\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.1575e-04\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.1566e-04\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 5.1429e-04\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.1543e-04\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.1184e-04\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.1059e-04\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.1102e-04\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.0915e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28ea04516a0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.0, random_state=42)\n",
    "X_train, y_train = X_reshape, Y\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "# Evaluate the model\n",
    "#loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "#print('Test loss:', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      0.776143\n",
       "High      0.771675\n",
       "Low       0.743642\n",
       "Volume    0.020203\n",
       "Name: 2024-04-30 00:00:00-04:00, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_inference.drop('Close')[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397.3362390546972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model(hist_inference.drop('Close')[:4].values.reshape((1, 1, hist_inference.drop('Close')[:4].shape[0])))\n",
    "yhat_unnormalized = pred.numpy().tolist()[0][0] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "#ytrue_unnmormalized = Y.values[-1] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "print(yhat_unnormalized)\n",
    "#now the predicted price is for the end of the day for 20th 4 2024 for msft. and the predicted price is 403.98\n",
    "# and actual end price was 399.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"MSFT\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = 'max', interval = '1d') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "rec = stock.recommendations #has the recommendations on what to do with the stock \n",
    "#print(rec)\n",
    "\n",
    "BS = stock.balancesheet #Has the balance sheet. \n",
    "#print(BS)\n",
    "\n",
    "news = stock.news #Has all of the news from the yahoo finance page \n",
    "#print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(hist.shape[0]), (hist['High'] + hist['Low'])/2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "High = hist.loc[:,'High']\n",
    "Low = hist.loc[:,'Low']\n",
    "Mid = (High+Low)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Mid[:9500]\n",
    "test = Mid[9500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "1. Clean up and ready the dataset for both Plan 1 and 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
