{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Kernel \n",
    "\n",
    "Name: spri (python 3.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello, world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENV Setup and Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import torch\n",
    "import sklearn\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YFinance Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"tsla\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = '60d', interval = '30m') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "#opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "#inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "#rec = stock.recommendations.to_dict(\"records\") #has the recommendations on what to do with the stock \n",
    "#print(rec)\n",
    "\n",
    "\n",
    "#news = stock.news #Has all of the news from the yahoo finance page \n",
    "#print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hist1 = hist['Close'].iloc[-100:].to_dict()\n",
    "for i in list(Hist1.keys()):\n",
    "    Hist1[str(i)] = Hist1.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2024-04-22 11:30:00-04:00': 141.60000610351562,\n",
       " '2024-04-22 12:00:00-04:00': 142.1342010498047,\n",
       " '2024-04-22 12:30:00-04:00': 141.87989807128906,\n",
       " '2024-04-22 13:00:00-04:00': 142.1699981689453,\n",
       " '2024-04-22 13:30:00-04:00': 142.8699951171875,\n",
       " '2024-04-22 14:00:00-04:00': 141.89199829101562,\n",
       " '2024-04-22 14:30:00-04:00': 142.05999755859375,\n",
       " '2024-04-22 15:00:00-04:00': 142.35000610351562,\n",
       " '2024-04-22 15:30:00-04:00': 142.02999877929688,\n",
       " '2024-04-23 09:30:00-04:00': 144.97999572753906,\n",
       " '2024-04-23 10:00:00-04:00': 144.75999450683594,\n",
       " '2024-04-23 10:30:00-04:00': 144.64410400390625,\n",
       " '2024-04-23 11:00:00-04:00': 145.66000366210938,\n",
       " '2024-04-23 11:30:00-04:00': 144.74000549316406,\n",
       " '2024-04-23 12:00:00-04:00': 146.87989807128906,\n",
       " '2024-04-23 12:30:00-04:00': 145.75,\n",
       " '2024-04-23 13:00:00-04:00': 145.6999969482422,\n",
       " '2024-04-23 13:30:00-04:00': 145.5399932861328,\n",
       " '2024-04-23 14:00:00-04:00': 145.41439819335938,\n",
       " '2024-04-23 14:30:00-04:00': 145.57980346679688,\n",
       " '2024-04-23 15:00:00-04:00': 145.02999877929688,\n",
       " '2024-04-23 15:30:00-04:00': 144.8699951171875,\n",
       " '2024-04-24 09:30:00-04:00': 162.62550354003906,\n",
       " '2024-04-24 10:00:00-04:00': 164.58299255371094,\n",
       " '2024-04-24 10:30:00-04:00': 161.9199981689453,\n",
       " '2024-04-24 11:00:00-04:00': 161.3300018310547,\n",
       " '2024-04-24 11:30:00-04:00': 160.03500366210938,\n",
       " '2024-04-24 12:00:00-04:00': 158.6199951171875,\n",
       " '2024-04-24 12:30:00-04:00': 159.74000549316406,\n",
       " '2024-04-24 13:00:00-04:00': 160.7899932861328,\n",
       " '2024-04-24 13:30:00-04:00': 161.97999572753906,\n",
       " '2024-04-24 14:00:00-04:00': 161.17999267578125,\n",
       " '2024-04-24 14:30:00-04:00': 160.64010620117188,\n",
       " '2024-04-24 15:00:00-04:00': 161.88499450683594,\n",
       " '2024-04-24 15:30:00-04:00': 162.17999267578125,\n",
       " '2024-04-25 09:30:00-04:00': 162.4600067138672,\n",
       " '2024-04-25 10:00:00-04:00': 165.49000549316406,\n",
       " '2024-04-25 10:30:00-04:00': 165.00999450683594,\n",
       " '2024-04-25 11:00:00-04:00': 166.4499969482422,\n",
       " '2024-04-25 11:30:00-04:00': 164.72000122070312,\n",
       " '2024-04-25 12:00:00-04:00': 163.65310668945312,\n",
       " '2024-04-25 12:30:00-04:00': 164.72630310058594,\n",
       " '2024-04-25 13:00:00-04:00': 164.6342010498047,\n",
       " '2024-04-25 13:30:00-04:00': 166.1199951171875,\n",
       " '2024-04-25 14:00:00-04:00': 166.14999389648438,\n",
       " '2024-04-25 14:30:00-04:00': 167.57000732421875,\n",
       " '2024-04-25 15:00:00-04:00': 169.36500549316406,\n",
       " '2024-04-25 15:30:00-04:00': 170.30999755859375,\n",
       " '2024-04-26 09:30:00-04:00': 168.27999877929688,\n",
       " '2024-04-26 10:00:00-04:00': 168.40310668945312,\n",
       " '2024-04-26 10:30:00-04:00': 169.8699951171875,\n",
       " '2024-04-26 11:00:00-04:00': 170.6699981689453,\n",
       " '2024-04-26 11:30:00-04:00': 171.42669677734375,\n",
       " '2024-04-26 12:00:00-04:00': 171.36000061035156,\n",
       " '2024-04-26 12:30:00-04:00': 171.72500610351562,\n",
       " '2024-04-26 13:00:00-04:00': 170.9499969482422,\n",
       " '2024-04-26 13:30:00-04:00': 169.5800018310547,\n",
       " '2024-04-26 14:00:00-04:00': 168.30999755859375,\n",
       " '2024-04-26 14:30:00-04:00': 167.1999969482422,\n",
       " '2024-04-26 15:00:00-04:00': 167.58529663085938,\n",
       " '2024-04-26 15:30:00-04:00': 168.2899932861328,\n",
       " '2024-04-29 09:30:00-04:00': 186.55569458007812,\n",
       " '2024-04-29 10:00:00-04:00': 185.61000061035156,\n",
       " '2024-04-29 10:30:00-04:00': 189.5200958251953,\n",
       " '2024-04-29 11:00:00-04:00': 192.77999877929688,\n",
       " '2024-04-29 11:30:00-04:00': 196.1407012939453,\n",
       " '2024-04-29 12:00:00-04:00': 198.5565948486328,\n",
       " '2024-04-29 12:30:00-04:00': 196.5653076171875,\n",
       " '2024-04-29 13:00:00-04:00': 195.6300048828125,\n",
       " '2024-04-29 13:30:00-04:00': 194.0399932861328,\n",
       " '2024-04-29 14:00:00-04:00': 193.2799072265625,\n",
       " '2024-04-29 14:30:00-04:00': 193.26499938964844,\n",
       " '2024-04-29 15:00:00-04:00': 192.35499572753906,\n",
       " '2024-04-29 15:30:00-04:00': 194.19500732421875,\n",
       " '2024-04-30 09:30:00-04:00': 189.3699951171875,\n",
       " '2024-04-30 10:00:00-04:00': 186.2960968017578,\n",
       " '2024-04-30 10:30:00-04:00': 185.5800018310547,\n",
       " '2024-04-30 11:00:00-04:00': 184.2799072265625,\n",
       " '2024-04-30 11:30:00-04:00': 183.7700958251953,\n",
       " '2024-04-30 12:00:00-04:00': 185.40370178222656,\n",
       " '2024-04-30 12:30:00-04:00': 185.24000549316406,\n",
       " '2024-04-30 13:00:00-04:00': 184.39999389648438,\n",
       " '2024-04-30 13:30:00-04:00': 184.99319458007812,\n",
       " '2024-04-30 14:00:00-04:00': 184.66000366210938,\n",
       " '2024-04-30 14:30:00-04:00': 184.1699981689453,\n",
       " '2024-04-30 15:00:00-04:00': 183.7050018310547,\n",
       " '2024-04-30 15:30:00-04:00': 183.3800048828125,\n",
       " '2024-05-01 09:30:00-04:00': 182.78990173339844,\n",
       " '2024-05-01 10:00:00-04:00': 180.44500732421875,\n",
       " '2024-05-01 10:30:00-04:00': 180.85499572753906,\n",
       " '2024-05-01 11:00:00-04:00': 180.4971923828125,\n",
       " '2024-05-01 11:30:00-04:00': 180.0,\n",
       " '2024-05-01 12:00:00-04:00': 181.36619567871094,\n",
       " '2024-05-01 12:30:00-04:00': 181.22000122070312,\n",
       " '2024-05-01 13:00:00-04:00': 180.00990295410156,\n",
       " '2024-05-01 13:30:00-04:00': 180.97999572753906,\n",
       " '2024-05-01 14:00:00-04:00': 182.3000030517578,\n",
       " '2024-05-01 14:30:00-04:00': 185.08999633789062,\n",
       " '2024-05-01 15:00:00-04:00': 183.7949981689453,\n",
       " '2024-05-01 15:30:00-04:00': 179.9949951171875}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-06 09:30:00-05:00</th>\n",
       "      <td>177.210007</td>\n",
       "      <td>185.250000</td>\n",
       "      <td>177.110001</td>\n",
       "      <td>183.863098</td>\n",
       "      <td>26336454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-06 10:00:00-05:00</th>\n",
       "      <td>183.899994</td>\n",
       "      <td>186.490005</td>\n",
       "      <td>182.789993</td>\n",
       "      <td>182.869904</td>\n",
       "      <td>16427320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-06 10:30:00-05:00</th>\n",
       "      <td>182.859894</td>\n",
       "      <td>185.500000</td>\n",
       "      <td>182.639999</td>\n",
       "      <td>185.039993</td>\n",
       "      <td>10993982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-06 11:00:00-05:00</th>\n",
       "      <td>185.050003</td>\n",
       "      <td>185.210007</td>\n",
       "      <td>183.190002</td>\n",
       "      <td>183.279999</td>\n",
       "      <td>8628863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-06 11:30:00-05:00</th>\n",
       "      <td>183.270004</td>\n",
       "      <td>183.720001</td>\n",
       "      <td>181.419998</td>\n",
       "      <td>181.498001</td>\n",
       "      <td>8537645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 13:30:00-04:00</th>\n",
       "      <td>179.998505</td>\n",
       "      <td>181.169998</td>\n",
       "      <td>179.860001</td>\n",
       "      <td>180.979996</td>\n",
       "      <td>3514188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 14:00:00-04:00</th>\n",
       "      <td>181.022903</td>\n",
       "      <td>182.479996</td>\n",
       "      <td>180.500000</td>\n",
       "      <td>182.300003</td>\n",
       "      <td>4818121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 14:30:00-04:00</th>\n",
       "      <td>182.330002</td>\n",
       "      <td>185.569901</td>\n",
       "      <td>180.750000</td>\n",
       "      <td>185.089996</td>\n",
       "      <td>9310471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 15:00:00-04:00</th>\n",
       "      <td>185.100006</td>\n",
       "      <td>185.860001</td>\n",
       "      <td>183.751999</td>\n",
       "      <td>183.794998</td>\n",
       "      <td>6526677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 15:30:00-04:00</th>\n",
       "      <td>183.794998</td>\n",
       "      <td>183.820007</td>\n",
       "      <td>179.979996</td>\n",
       "      <td>179.994995</td>\n",
       "      <td>9553174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Datetime                                                                    \n",
       "2024-02-06 09:30:00-05:00  177.210007  185.250000  177.110001  183.863098   \n",
       "2024-02-06 10:00:00-05:00  183.899994  186.490005  182.789993  182.869904   \n",
       "2024-02-06 10:30:00-05:00  182.859894  185.500000  182.639999  185.039993   \n",
       "2024-02-06 11:00:00-05:00  185.050003  185.210007  183.190002  183.279999   \n",
       "2024-02-06 11:30:00-05:00  183.270004  183.720001  181.419998  181.498001   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-05-01 13:30:00-04:00  179.998505  181.169998  179.860001  180.979996   \n",
       "2024-05-01 14:00:00-04:00  181.022903  182.479996  180.500000  182.300003   \n",
       "2024-05-01 14:30:00-04:00  182.330002  185.569901  180.750000  185.089996   \n",
       "2024-05-01 15:00:00-04:00  185.100006  185.860001  183.751999  183.794998   \n",
       "2024-05-01 15:30:00-04:00  183.794998  183.820007  179.979996  179.994995   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Datetime                                                      \n",
       "2024-02-06 09:30:00-05:00  26336454        0.0           0.0  \n",
       "2024-02-06 10:00:00-05:00  16427320        0.0           0.0  \n",
       "2024-02-06 10:30:00-05:00  10993982        0.0           0.0  \n",
       "2024-02-06 11:00:00-05:00   8628863        0.0           0.0  \n",
       "2024-02-06 11:30:00-05:00   8537645        0.0           0.0  \n",
       "...                             ...        ...           ...  \n",
       "2024-05-01 13:30:00-04:00   3514188        0.0           0.0  \n",
       "2024-05-01 14:00:00-04:00   4818121        0.0           0.0  \n",
       "2024-05-01 14:30:00-04:00   9310471        0.0           0.0  \n",
       "2024-05-01 15:00:00-04:00   6526677        0.0           0.0  \n",
       "2024-05-01 15:30:00-04:00   9553174        0.0           0.0  \n",
       "\n",
       "[780 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179.99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['currentPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Timestamp('2024-03-31 00:00:00'): {'Total Revenue': 21301000000.0, 'Gross Profit': 3696000000.0, 'Net Income': 1129000000.0, 'Cost Of Revenue': 17605000000.0, 'Operating Revenue': 21301000000.0, 'Total Expenses': 20130000000.0}, Timestamp('2023-12-31 00:00:00'): {'Total Revenue': 25167000000.0, 'Gross Profit': 4438000000.0, 'Net Income': 7930000000.0, 'Cost Of Revenue': 20729000000.0, 'Operating Revenue': 25167000000.0, 'Total Expenses': 23103000000.0}, Timestamp('2023-09-30 00:00:00'): {'Total Revenue': 23350000000.0, 'Gross Profit': 4178000000.0, 'Net Income': 1853000000.0, 'Cost Of Revenue': 19172000000.0, 'Operating Revenue': 23350000000.0, 'Total Expenses': 21586000000.0}, Timestamp('2023-06-30 00:00:00'): {'Total Revenue': 24927000000.0, 'Gross Profit': 4533000000.0, 'Net Income': 2703000000.0, 'Cost Of Revenue': 20394000000.0, 'Operating Revenue': 24927000000.0, 'Total Expenses': 22528000000.0}, Timestamp('2023-03-31 00:00:00'): {'Total Revenue': 23329000000.0, 'Gross Profit': 4511000000.0, 'Net Income': 2513000000.0, 'Cost Of Revenue': 18818000000.0, 'Operating Revenue': 23329000000.0, 'Total Expenses': 20665000000.0}}\n",
      "{'2024-03-31 00:00:00': {'Total Revenue': 21301000000.0, 'Gross Profit': 3696000000.0, 'Net Income': 1129000000.0, 'Cost Of Revenue': 17605000000.0, 'Operating Revenue': 21301000000.0, 'Total Expenses': 20130000000.0}, '2023-12-31 00:00:00': {'Total Revenue': 25167000000.0, 'Gross Profit': 4438000000.0, 'Net Income': 7930000000.0, 'Cost Of Revenue': 20729000000.0, 'Operating Revenue': 25167000000.0, 'Total Expenses': 23103000000.0}, '2023-09-30 00:00:00': {'Total Revenue': 23350000000.0, 'Gross Profit': 4178000000.0, 'Net Income': 1853000000.0, 'Cost Of Revenue': 19172000000.0, 'Operating Revenue': 23350000000.0, 'Total Expenses': 21586000000.0}, '2023-06-30 00:00:00': {'Total Revenue': 24927000000.0, 'Gross Profit': 4533000000.0, 'Net Income': 2703000000.0, 'Cost Of Revenue': 20394000000.0, 'Operating Revenue': 24927000000.0, 'Total Expenses': 22528000000.0}, '2023-03-31 00:00:00': {'Total Revenue': 23329000000.0, 'Gross Profit': 4511000000.0, 'Net Income': 2513000000.0, 'Cost Of Revenue': 18818000000.0, 'Operating Revenue': 23329000000.0, 'Total Expenses': 20665000000.0}}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "select_col = stock.quarterly_financials.loc[['Total Revenue','Gross Profit', 'Net Income' ,'Cost Of Revenue', 'Operating Revenue', 'Total Expenses']].to_dict()\n",
    "print(select_col)\n",
    "for i in list(select_col.keys()):\n",
    "    select_col[str(i)] = select_col.pop(i)\n",
    "print(select_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.info\n",
    "key_to_display = ['city', 'state', 'country', 'industry', 'website', 'phone', 'companyOfficers', 'open' , 'previousClose', 'Percentage diff', #for this % diff, just find the how percentage is the opena nd prev close diff\n",
    "                  'marketCap', 'currency', 'longName', 'timeZoneFullName', 'recommendationKey'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['companyOfficers'][0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_price = info.get('currentPrice')\n",
    "old_price = stock.info['previousClose']\n",
    "percentage_change = ((new_price - old_price) / old_price) * 100\n",
    "print(str(percentage_change))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.info['recommendationKey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.major_holders.to_dict()['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_to_display = ['title', 'publisher', 'link', 'relatedTickers', 'thumbnail'] #thumbnail is a dict and you gon get the url like this. stock.news[1]['thumbnail']['resolutions'][0]['url']\n",
    "\n",
    "stock.news[1]['thumbnail']['resolutions'][0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down = stock.upgrades_downgrades\n",
    "down.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.upgrades_downgrades.iloc[:3].reset_index().loc[:, ['Firm', 'ToGrade', 'GradeDate']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.quarterly_financials.loc[['Total Revenue','Gross Profit', 'Net Income' ,'Cost Of Revenue', 'Operating Revenue', 'Total Expenses']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Total Revenue','Gross Profit', 'Net Income' ,'Cost Of Revenue', 'Operating Revenue', 'Total Expenses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINKS:\n",
    "\n",
    "https://pypi.org/project/yfinance/\n",
    "\n",
    "https://finance.yahoo.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explorations and Idea of Attack \n",
    "\n",
    "Now, we got all of these details, how are they going to be used in our model, and what is our model? \n",
    "\n",
    "Data:\n",
    "Open: Opening stock price of the unit time \n",
    "Close: Closing stock price of the unit time \n",
    "High: Highest stock price of the unit time\n",
    "Low: Lowest stock price of the unit time \n",
    "Volume: Amount of stocks sold in that unit time.\n",
    "\n",
    "Plan of Attack :\n",
    "\n",
    "Plan 1: Time series graph: Basically take the Open and Close values and then find the mid value and plot a time series graph and then involue LSTMS for time series grpahs. Good for long forcasts for over a week in the future or so. (Link 2)\n",
    "\n",
    "Plan 2: Timely Update Graph: Take the open, high and low as X and Close as Y and perform normal LSTM operations. (Link 3)\n",
    "\n",
    "If you are predicting intraday trading and your interval is 1 min, you need to automatically cache and update the timer and predict the values for the minute. So, you might have to turn your model to Train mode and then feed in this additional info and then turn it back to test mode and predict the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized = (hist - hist.min()) / (hist.max() - hist.min())\n",
    "\n",
    "Y = hist_normalized['Close']\n",
    "X = hist_normalized.drop('Close', axis=1)\n",
    "X = X.drop('Dividends', axis=1)\n",
    "X = X.drop('Stock Splits', axis=1)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values = X.values\n",
    "\n",
    "#1 is the time step, if you need the lstm to look back the past 1 row and then predict the closing price. then the time step should be 1. \n",
    "#if you want the lstm to look back around the past 5 records and then the predict the closing price, then turn the 1 into a 5\n",
    "X_reshape = X_Values.reshape((X_Values.shape[0], 1, X_Values.shape[1]))\n",
    "print(X_reshape.shape)\n",
    "X_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Links\n",
    "\n",
    "1. https://colab.research.google.com/drive/18WiSw1K0BW3jOKO56vxn11Fo9IyOuRjh#scrollTo=2SoQJk5BYOas\n",
    "\n",
    "2. https://www.datacamp.com/tutorial/lstm-python-stock-market \n",
    "\n",
    "3. https://medium.com/@prajjwalchauhan94017/stock-prediction-and-forecasting-using-lstm-long-short-term-memory-9ff56625de73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (For plan 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.0, random_state=42)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inference = np.array([[[0.09978002, 0.07600253, 0.10062503, 0.        ]]])\n",
    "pred = model(Inference)\n",
    "yhat_unnormalized = pred.numpy().tolist()[0][0] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "ytrue_unnmormalized = Y.values[-1] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "print(yhat_unnormalized, ytrue_unnmormalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: The data isn't predicting the future but the time that is already passed. \n",
    "\n",
    "* What you need to do is, instead of giving the y as the close price of that row, give the y as the close price of the next row. aka the close price of the next time step. basically you are removing the top value of the close and shifting the total col up by 1 row (this means the first x is pared with the 2nd y and 2nd x is pared by 3rd y and like that the last x won't have an y value) and removing the last x and the using that as the inference x. This might not need testing dataset. \n",
    "\n",
    "\n",
    "* or keep everything the same and then take the current, open, high and low price by web scrapping and then predict using that. \n",
    "\n",
    "* what you need to is, take 1m as the interval and turn the time step into 30 (so each input is around 30 mintues' worth of data and then you predict the close of the once every 30 mins) (Didn't do exactly this but did 30 min interval and then turn that into 1.5 hour time step.)\n",
    "\n",
    "\n",
    "\n",
    "* Or just use the open price as x and then web scrap the current price and name it as current open price and then get the y value\n",
    "\n",
    "\n",
    "Not sure if all of these will work, but try all of them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 1 (SORTA WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"GC=F\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = '60d', interval = '30m') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "#opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "#inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "#rec = stock.recommendations #has the recommendations on what to do with the stock \n",
    "#print(rec)\n",
    "\n",
    "#BS = stock.balancesheet #Has the balance sheet. \n",
    "#print(BS)\n",
    "\n",
    "#news = stock.news #Has all of the news from the yahoo finance page \n",
    "#print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized .index = pd.to_datetime(hist_normalized .index)\n",
    "\n",
    "# Resample the data to hourly intervals\n",
    "hourly_data = hist_normalized .resample('H').agg({'Open': 'first',\n",
    "                                      'High': 'max',\n",
    "                                      'Low': 'min',\n",
    "                                      'Close': 'last',\n",
    "                                      'Volume': 'sum'})\n",
    "\n",
    "# The 'Dividends' and 'Stock Splits' columns are not applicable for hourly data\n",
    "# and can be dropped or handled as needed\n",
    "\n",
    "hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized = (hist - hist.min()) / (hist.max() - hist.min())\n",
    "\n",
    "Y = hist_normalized['Close'].iloc[1:]\n",
    "X = hist_normalized.drop('Close', axis=1)\n",
    "X = X.drop('Dividends', axis=1)\n",
    "X = X.drop('Stock Splits', axis=1)\n",
    "Inference = X.iloc[-1]\n",
    "X = X.iloc[:-1]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inference.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Values = X.values\n",
    "In = Inference.values\n",
    "In = In.reshape((1, 1, In.shape[0]))\n",
    "\n",
    "#1 is the time step, if you need the lstm to look back the past 1 row and then predict the closing price. then the time step should be 1. \n",
    "#if you want the lstm to look back around the past 5 records and then the predict the closing price, then turn the 1 into a 5\n",
    "X_reshape = X_Values.reshape((X_Values.shape[0], 1, X_Values.shape[1]))\n",
    "print(X_reshape.shape)\n",
    "X_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the data\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.0, random_state=42)\n",
    "# X_train, y_train = X_reshape, Y\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "\n",
    "# # Define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=100)\n",
    "# # Evaluate the model\n",
    "# #loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #print('Test loss:', loss)\n",
    "\n",
    "## Test 2 \n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "\n",
    "def custom_activation(x, beta = 1):\n",
    "        return (K.sigmoid(beta * x) * x)\n",
    "\n",
    "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.15, random_state=42)\n",
    "#X_train, y_train = X_reshape, tY\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Activation(custom_activation,name = \"Swish\"))\n",
    "model.add(Dense(1))\n",
    "#print(model.summary())\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(np.array([[Inference.values.tolist()]]))\n",
    "yhat_unnormalized = pred.numpy().tolist()[0][0] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "#ytrue_unnmormalized = 0.02574494974900854 * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "print(yhat_unnormalized) #this value is the predicted value that is in the next timestep future.\n",
    "#that is the price of the stock in around 2024-04-19 16:00:00-40:00. the predicted price was 398.227. \n",
    "# the actual price at that time was 399.12\n",
    "# the actual stock is actually decreasing.\n",
    "\n",
    "#Now doing for an hour. the the predicted was 398.44\n",
    "# the actual price was. 398.38. which is not bad at all!!!!!!!!! \n",
    "\n",
    "\n",
    "#Test number two. \n",
    "# one hour. the predicted was 399.94. the true was 399.119 and the price is increasing\n",
    "# 30 mins. The predicted was 399.03 and the true was 399.109. Both were done for msft stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 2 (Don't think will work.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 3 (Works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"msft\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = '1mo', interval = '30m') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "#opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "#inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "rec = stock.recommendations #has the recommendations on what to do with the stock \n",
    "print(rec)\n",
    "\n",
    "#BS = stock.balancesheet #Has the balance sheet. \n",
    "#print(BS)\n",
    "\n",
    "news = stock.news #Has all of the news from the yahoo finance page \n",
    "print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized = (hist - hist.min()) / (hist.max() - hist.min())\n",
    "\n",
    "Y = hist_normalized['Close'].iloc[1:]\n",
    "X = hist_normalized.drop('Close', axis=1)\n",
    "X = X.drop('Dividends', axis=1)\n",
    "X = X.drop('Stock Splits', axis=1)\n",
    "Inference = X.iloc[-1]\n",
    "X = X.iloc[:-1]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming X_Values is your original data\n",
    "X_Values = X.values\n",
    "\n",
    "# Initialize an empty list to hold the reshaped data\n",
    "X_reshape = []\n",
    "\n",
    "TimeStep = 0 #0 means only the current row, 1 means 1 previous row included. 2 means 2 previous rows included. \n",
    "# Loop through each row in the dataset\n",
    "for i in range(TimeStep, X_Values.shape[0]):\n",
    "    # Create a window of data that includes the current row and the two preceding rows\n",
    "    window = X_Values[i-TimeStep:i+1]\n",
    "    # Reshape the window to fit the LSTM model's input shape\n",
    "    window_reshaped = window.reshape((1, window.shape[0], window.shape[1]))\n",
    "    # Append the reshaped window to the list\n",
    "    X_reshape.append(window_reshaped)\n",
    "\n",
    "# Convert the list of reshaped windows to a NumPy array\n",
    "X_reshape = np.concatenate(X_reshape, axis=0)\n",
    "\n",
    "print(X_reshape.shape)\n",
    "\n",
    "Y = Y.iloc[TimeStep:]\n",
    "\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.0, random_state=42)\n",
    "X_train, y_train = X_reshape, Y\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "# Evaluate the model\n",
    "#loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "#print('Test loss:', loss)\n",
    "\n",
    "## Test 2 \n",
    "# from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "# from keras import backend as K\n",
    "# from keras.layers import Activation\n",
    "\n",
    "# def custom_activation(x, beta = 1):\n",
    "#         return (K.sigmoid(beta * x) * x)\n",
    "\n",
    "# get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
    "\n",
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.15, random_state=42)\n",
    "# #X_train, y_train = X_reshape, tY\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "\n",
    "# # Define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(Activation(custom_activation,name = \"Swish\"))\n",
    "# model.add(Dense(1))\n",
    "# #print(model.summary())\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=100)\n",
    "# # Evaluate the model\n",
    "# loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Test loss:', loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In = X_reshape[-1]\n",
    "In = np.delete(In, 0, axis=0)\n",
    "In = np.append(In, np.array([Inference.values.tolist()]), axis=0)\n",
    "In = In[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(In)\n",
    "yhat_unnormalized = pred.numpy().tolist()[0][0] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "#ytrue_unnmormalized = 0.02574494974900854 * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "print(yhat_unnormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 4 (Should try)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 5 (1 Day model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"MSFT\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = '1y', interval = '1d') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "rec = stock.recommendations #has the recommendations on what to do with the stock \n",
    "#print(rec)\n",
    "\n",
    "BS = stock.balancesheet #Has the balance sheet. \n",
    "#print(BS)\n",
    "\n",
    "news = stock.news #Has all of the news from the yahoo finance page \n",
    "#print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_normalized = (hist - hist.min()) / (hist.max() - hist.min())\n",
    "hist_inference = hist_normalized.iloc[-1]\n",
    "hist_normalized = hist_normalized.iloc[:-1]\n",
    "\n",
    "Y = hist_normalized['Close']\n",
    "X = hist_normalized.drop('Close', axis=1)\n",
    "X = X.drop('Dividends', axis=1)\n",
    "X = X.drop('Stock Splits', axis=1)\n",
    "\n",
    "\n",
    "X_Values = X.values\n",
    "\n",
    "#1 is the time step, if you need the lstm to look back the past 1 row and then predict the closing price. then the time step should be 1. \n",
    "#if you want the lstm to look back around the past 5 records and then the predict the closing price, then turn the 1 into a 5\n",
    "X_reshape = X_Values.reshape((X_Values.shape[0], 1, X_Values.shape[1]))\n",
    "print(X_reshape.shape)\n",
    "X_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshape, Y, test_size=0.0, random_state=42)\n",
    "X_train, y_train = X_reshape, Y\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "# Evaluate the model\n",
    "#loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "#print('Test loss:', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_inference.drop('Close')[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = model(hist_inference.drop('Close')[:4].values.reshape((1, 1, hist_inference.drop('Close')[:4].shape[0])))\n",
    "yhat_unnormalized = pred.numpy().tolist()[0][0] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "#ytrue_unnmormalized = Y.values[-1] * (hist['Close'].max() - hist['Close'].min()) + hist['Close'].min()\n",
    "print(yhat_unnormalized)\n",
    "#now the predicted price is for the end of the day for 20th 4 2024 for msft. and the predicted price is 403.98\n",
    "# and actual end price was 399.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"MSFT\")\n",
    "\n",
    "info = stock.info # has all the additional info about the company but not required for the model\n",
    "\n",
    "hist = stock.history(period = 'max', interval = '1d') #has the following cols: Data, Open, High, Low, Close, Vol, Dividends and \n",
    "#stock splits (dividends and stock splits aren't really required for the model)\n",
    "\n",
    "#print(hist) #To print the dataset. \n",
    "\n",
    "#Additional infomation \n",
    "#print(stock.options) #this shows the list of options' exp dates\n",
    "opt = stock.option_chain(stock.options[0]) #use like this or stock.option_chain(\"YYYY-MM-DD\") Gives details on the Options present. \n",
    "#print(opt.calls)\n",
    "#print(opt.puts)\n",
    "\n",
    "inc_stmt = stock.income_stmt #Has the income statement with the total revenue of the company\n",
    "#print(inc_stmt)\n",
    "\n",
    "rec = stock.recommendations #has the recommendations on what to do with the stock \n",
    "#print(rec)\n",
    "\n",
    "BS = stock.balancesheet #Has the balance sheet. \n",
    "#print(BS)\n",
    "\n",
    "news = stock.news #Has all of the news from the yahoo finance page \n",
    "#print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(hist.shape[0]), (hist['High'] + hist['Low'])/2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "High = hist.loc[:,'High']\n",
    "Low = hist.loc[:,'Low']\n",
    "Mid = (High+Low)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Mid[:9500]\n",
    "test = Mid[9500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "1. Clean up and ready the dataset for both Plan 1 and 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
